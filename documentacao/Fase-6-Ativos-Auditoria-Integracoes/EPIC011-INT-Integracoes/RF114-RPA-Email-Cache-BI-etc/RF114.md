# RF-114: Integrações Avançadas - RPA, Email, Cache e BI

**Versão**: 1.0 | **Data**: 2025-12-28
**RF Relacionado**: RF-105, RF-108, RF-109 | **EPIC**: EPIC011-INT-Integracoes
**Fase**: Fase 6 - Ativos, Auditoria e Integrações

---

## 1. RESUMO EXECUTIVO

### 1.1 Descrição Geral

Este requisito especifica o **Hub de Integrações Avançadas** do sistema IControlIT, responsável por automatizar processos críticos de importação de dados, comunicação por email, otimização de performance via cache distribuído e integração com ferramentas de Business Intelligence (Power BI e Tableau). O módulo fornece capacidades de Robotic Process Automation (RPA), processamento de emails, gerenciamento de cache com invalidação inteligente, orquestração de APIs, ETL para DataWarehouse e publicação de datasets em plataformas BI.

O RF114 é o coração técnico que permite a automação de processos transversais ao negócio, desde a importação noturna de faturas de operadoras de telecom até a publicação automática de dashboards executivos em Power BI.

### 1.2 Importância Estratégica

O módulo de Integrações Avançadas é crítico para:
- **Automação Processual**: Eliminação de processos manuais (RPA para faturas, emails automáticos), reduzindo trabalho operacional em até 40%
- **Performance e Escalabilidade**: Cache distribuído (Redis) reduz latência de APIs externas em até 80% (24h TTL)
- **Conformidade Regulatória**: Auditoria completa de todas operações de integração (LGPD, SOX), retenção por 5 anos
- **Business Intelligence**: Publicação automática diária de datasets em Power BI/Tableau para dashboards executivos
- **Integrações de Mercado**: Suporte nativo a Selenium/Playwright (RPA), SendGrid (email), Azure Service Bus (mensageria), Azure Data Factory (ETL)

### 1.3 Conceitos Fundamentais

**RPA (Robotic Process Automation)**: Automação de processos repetitivos usando navegadores web controlados (Selenium/Playwright). Exemplo: Importar faturas do portal de operadoras telecom sem APIs nativas.
- Execução: 22h-6h (fora do horário comercial, conforme RN-INT-114-01)
- Logs: Auditoria completa de cada tentativa (sucesso/falha)

**Email Automático**: Envio de relatórios, alertas e notificações usando SendGrid ou MailKit com templates HTML responsivos.
- Validação de remetente: Whitelist/Blacklist (RN-INT-114-03)
- Template HTML: Logo do cliente (RN-INT-114-02)

**Cache Distribuído**: Redis com TTL de 24h para APIs externas (CEP, CNPJ, Cotação, etc.).
- Reduz chamadas desnecessárias
- Fallback automático se Redis indisponível

**Power BI/Tableau Integration**: Publicação automática de datasets diariamente via REST API.
- Hangfire para agendamento (diariamente às 05h)
- Autenticação OAuth 2.0

**Webhooks**: Notificações em tempo real para eventos do sistema.
- Validação HMAC-SHA256 (RN-INT-114-06)
- Retry automático com backoff exponencial

**API Gateway**: Orquestração centralizada de chamadas a APIs externas com rate limiting.
- 1.000 req/min por cliente (RN-INT-114-07)
- Circuit breaker para proteção

**Message Queue (Azure Service Bus)**: Garantia de entrega (at-least-once) com suporte a DLQ (Dead Letter Queue).
- Topics para eventos do sistema
- Subscriptions para processamento assíncrono

**ETL (Extract, Transform, Load)**: Processamento em lotes (10.000 registros por vez) para DataWarehouse.
- Azure Data Factory ou SSIS (opcional)

### 1.4 Legado vs Modernizado

| Aspecto | Legado (VB.NET) | Modernizado (.NET 10 + Angular) |
|---------|-----------------|--------------------------------|
| **RPA** | Código VB6 com IE (obsoleto) | Selenium/Playwright com .NET 10, suporte Edge/Chrome |
| **Email** | Emails simples texto via SMTP direto | SendGrid com templates HTML responsivos, tracking |
| **Cache** | Cache em memória (AppDomain único) | Redis distribuído com TTL inteligente e invalidação |
| **BI Integration** | Exports manuais em Excel/CSV | Power BI REST API com publicação automática diária (Hangfire) |
| **Message Queue** | MSMQ (Windows only) | Azure Service Bus (cloud-native, cross-platform) |
| **ETL** | SSIS com stored procedures | Azure Data Factory + .NET jobs para transformação |
| **Auditoria** | Logs em arquivo de texto | Auditoria estruturada em banco com retenção política (5 anos) |
| **Segurança** | Sem validação de webhooks | HMAC-SHA256 + rate limiting + circuit breaker |

### 1.5 Funcionalidades Principais

1. **RPA para Importação de Faturas** - Acesso automatizado aos portais de operadoras (Vivo, Claro, TIM, Oi) com Selenium/Playwright
2. **Envio Automático de Emails** - Relatórios, alertas e notificações com templates HTML e tracking
3. **Parsing de Emails** - Leitura de caixas de entrada com validação de remetente e extração de dados estruturados
4. **Cache Distribuído (Redis)** - Otimização de APIs externas (CEP, CNPJ, Cotação) com TTL de 24h
5. **Integração Power BI** - Publicação automática diária de datasets via REST API
6. **Integração Tableau** - Export de dados estruturados via Tableau API
7. **Webhooks Validados** - Notificações em tempo real com HMAC-SHA256 e retry automático
8. **API Gateway** - Orquestração centralizada com rate limiting (1.000 req/min) e circuit breaker
9. **ETL para DataWarehouse** - Processamento em lotes (10.000 registros) com transformação de dados
10. **Message Queue** - Azure Service Bus com topics, subscriptions e DLQ para garantia de entrega (at-least-once)

---

## 2. REGRAS DE NEGÓCIO

### RN-INT-114-01: RPA Deve Executar Fora de Horário Comercial

**Descrição**: Todos os jobs RPA (importação de faturas, consultas a portais externos) devem ser executados entre 22h e 6h UTC, evitando conflitos com o horário comercial.

**Justificativa**:
- Minimize impacto na performance do sistema durante pico de uso
- Portais de operadoras têm menor latência fora do horário comercial
- Facilita resolução de problemas em horário comercial

**Implementação**:
```csharp
public class RpaScheduleService
{
    private readonly IHangfireScheduler _scheduler;
    private readonly ILogger<RpaScheduleService> _logger;

    public async Task ScheduleRpaJobAsync(string jobName, Func<Task> jobAction)
    {
        var utcNow = DateTime.UtcNow;
        var hour = utcNow.Hour;

        // Validar se está dentro da janela 22h-6h
        bool isValidWindow = (hour >= 22 || hour < 6);

        if (!isValidWindow)
        {
            _logger.LogWarning($"RPA job '{jobName}' fora da janela permitida. Agendado para próxima janela.");

            // Agendar para próximas 22h
            var nextRun = CalculateNextRun(utcNow);
            RecurringJob.AddOrUpdate(
                jobName,
                jobAction,
                Cron.Daily(22, 0), // 22h UTC todos os dias
                TimeZoneInfo.Utc
            );
        }
        else
        {
            // Executar imediatamente
            await jobAction();
        }
    }

    private DateTime CalculateNextRun(DateTime utcNow)
    {
        if (utcNow.Hour < 22)
        {
            return utcNow.Date.AddHours(22);
        }
        else
        {
            return utcNow.AddDays(1).Date.AddHours(22);
        }
    }
}
```

**Exemplos**:
- ✓ Válido: Job executado às 23:45 (dentro da janela)
- ✓ Válido: Job agendado para 22:00 quando requisitado às 14:00
- ✗ Inválido: Tentativa de executar RPA às 10:00 (rejeitada, reagendada para 22:00)

---

### RN-INT-114-02: Email Deve Usar Template HTML com Logo do Cliente

**Descrição**: Todo email enviado via SendGrid ou MailKit deve conter um template HTML responsivo com logo da empresa (cliente), headers personalizados e footer com dados de contato.

**Justificativa**:
- Marca profissional consistente
- Emails responsivos em mobile
- Facilita identificação do cliente remetente
- Suporte a A/B testing de templates

**Implementação**:
```csharp
public class EmailTemplateService
{
    private readonly IClientRepository _clientRepository;
    private readonly SendGridClient _sendGridClient;

    public async Task<EmailTemplate> BuildEmailTemplateAsync(
        string clienteId,
        string templateKey,
        Dictionary<string, string> variables)
    {
        var cliente = await _clientRepository.GetByIdAsync(clienteId);

        var template = new EmailTemplate
        {
            Subject = variables.GetValueOrDefault("subject", "IControlIT"),
            HtmlContent = GenerateHtmlContent(cliente, templateKey, variables),
            PlainTextContent = GeneratePlainText(templateKey, variables),
            From = new EmailAddress("noreply@icontrolit.com.br", "IControlIT")
        };

        return template;
    }

    private string GenerateHtmlContent(
        ClienteModel cliente,
        string templateKey,
        Dictionary<string, string> variables)
    {
        var html = @$"
<!DOCTYPE html>
<html>
<head>
    <meta charset='UTF-8'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0'>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 0; padding: 0; }}
        .container {{ max-width: 600px; margin: 0 auto; background: #f5f5f5; }}
        .header {{ background: #ffffff; padding: 20px; text-align: center; border-bottom: 2px solid #007bff; }}
        .logo {{ max-width: 200px; height: auto; }}
        .content {{ background: #ffffff; padding: 30px; }}
        .footer {{ background: #f5f5f5; padding: 15px; text-align: center; font-size: 12px; color: #666; }}
    </style>
</head>
<body>
    <div class='container'>
        <div class='header'>
            <img src='{cliente.LogoUrl}' alt='{cliente.Nome}' class='logo'>
        </div>
        <div class='content'>
            {RenderTemplateContent(templateKey, variables)}
        </div>
        <div class='footer'>
            <p><strong>{cliente.Nome}</strong></p>
            <p>{cliente.Contato} | {cliente.Telefone} | {cliente.Email}</p>
            <p>© {DateTime.Now.Year} - Todos os direitos reservados</p>
        </div>
    </div>
</body>
</html>
";
        return html;
    }

    private string RenderTemplateContent(
        string templateKey,
        Dictionary<string, string> variables)
    {
        return templateKey switch
        {
            "FATURA_IMPORTADA" => $@"
                <h2>Fatura Importada com Sucesso</h2>
                <p>Prezado,</p>
                <p>A fatura <strong>{variables["invoiceNumber"]}</strong> foi importada com sucesso.</p>
                <p><strong>Período:</strong> {variables["period"]}</p>
                <p><strong>Valor:</strong> R$ {variables["amount"]}</p>
            ",
            "ALERTA_CONSUMO" => $@"
                <h2>Alerta de Consumo</h2>
                <p>Seu consumo atingiu <strong>{variables["percentage"]}%</strong> do limite orçado.</p>
            ",
            _ => "<p>Template desconhecido</p>"
        };
    }
}
```

**Exemplos**:
- ✓ Válido: Email com logo, header personalizado, conteúdo dinâmico, footer com contato
- ✗ Inválido: Email sem logo ou template genérico

---

### RN-INT-114-03: Email Parsing Deve Validar Remetente (Whitelist/Blacklist)

**Descrição**: Ao processar emails de entrada (parsing), validar remetente contra whitelist (permite) e blacklist (rejeita). Rejeitar automaticamente emails de remetentes bloqueados.

**Justificativa**:
- Segurança: Evitar phishing e emails maliciosos
- Conformidade: Permitir apenas remetentes autorizados
- Eficiência: Descartar spam automaticamente

**Implementação**:
```csharp
public class EmailParsingService
{
    private readonly IEmailValidationRepository _validationRepository;
    private readonly IMailKitService _mailKitService;

    public async Task<EmailParsingResult> ParseEmailAsync(MailMessage mailMessage)
    {
        var senderEmail = mailMessage.From.Address;

        // Validar contra blacklist
        var isBlacklisted = await _validationRepository.IsBlacklistedAsync(senderEmail);
        if (isBlacklisted)
        {
            return new EmailParsingResult
            {
                Success = false,
                Reason = $"Sender '{senderEmail}' is blacklisted",
                ShouldDelete = true
            };
        }

        // Validar contra whitelist (se whitelist existe, deve estar nela)
        var whitelist = await _validationRepository.GetWhitelistAsync();
        if (whitelist.Any() && !whitelist.Contains(senderEmail))
        {
            return new EmailParsingResult
            {
                Success = false,
                Reason = $"Sender '{senderEmail}' is not whitelisted",
                ShouldDelete = false // Mover para pasta de quarentena
            };
        }

        // Extrair dados da fatura (exemplo)
        var extractedData = ExtractInvoiceDataFromEmail(mailMessage.Body);

        return new EmailParsingResult
        {
            Success = true,
            SenderEmail = senderEmail,
            ExtractedData = extractedData,
            ReceiveDate = mailMessage.Date
        };
    }

    private Dictionary<string, string> ExtractInvoiceDataFromEmail(string htmlBody)
    {
        var result = new Dictionary<string, string>();

        // Usar regex para extrair número de fatura, período, valor, etc.
        var invoiceNumberMatch = Regex.Match(htmlBody, @"Fatura:\s*(\d+)");
        if (invoiceNumberMatch.Success)
        {
            result["InvoiceNumber"] = invoiceNumberMatch.Groups[1].Value;
        }

        var periodMatch = Regex.Match(htmlBody, @"Período:\s*([\d/]+)\s*a\s*([\d/]+)");
        if (periodMatch.Success)
        {
            result["PeriodStart"] = periodMatch.Groups[1].Value;
            result["PeriodEnd"] = periodMatch.Groups[2].Value;
        }

        var amountMatch = Regex.Match(htmlBody, @"Total:\s*R\$\s*([\d.,]+)");
        if (amountMatch.Success)
        {
            result["Amount"] = amountMatch.Groups[1].Value;
        }

        return result;
    }
}

public class EmailParsingResult
{
    public bool Success { get; set; }
    public string Reason { get; set; }
    public string SenderEmail { get; set; }
    public Dictionary<string, string> ExtractedData { get; set; }
    public DateTime ReceiveDate { get; set; }
    public bool ShouldDelete { get; set; }
}
```

**Exemplos**:
- ✓ Válido: Email de faturas@vivo.com.br (whitelisted) → processado
- ✗ Inválido: Email de phishing@malware.com (blacklisted) → deletado
- ✗ Inválido: Email de desconhecido@example.com (não em whitelist) → quarentena

---

### RN-INT-114-04: Cache de API Externa Válido por 24 Horas

**Descrição**: Resultados de chamadas a APIs externas (CEP, CNPJ, Cotação) devem ser cacheados em Redis com TTL de 24 horas. Se Redis indisponível, fazer fallback para chamada direta.

**Justificativa**:
- Reduz latência em até 80%
- Evita throttling de APIs externas
- Fallback automático garante disponibilidade
- Invalidação inteligente por tipo de dado

**Implementação**:
```csharp
public class ExternalApiCacheService
{
    private readonly IRedisCache _redisCache;
    private readonly IHttpClientFactory _httpClientFactory;
    private readonly ILogger<ExternalApiCacheService> _logger;
    private const int CACHE_TTL_HOURS = 24;

    public async Task<T> GetOrFetchAsync<T>(
        string cacheKey,
        Func<Task<T>> fetchFunc,
        string clienteId) where T : class
    {
        try
        {
            // Tentar obter do cache
            var cached = await _redisCache.GetAsync<T>(cacheKey);
            if (cached != null)
            {
                _logger.LogInformation($"Cache hit para chave '{cacheKey}' (cliente: {clienteId})");
                return cached;
            }

            // Não estava em cache, buscar
            var data = await fetchFunc();

            // Armazenar no cache com TTL
            await _redisCache.SetAsync(cacheKey, data, TimeSpan.FromHours(CACHE_TTL_HOURS));

            _logger.LogInformation($"Dado cacheado: '{cacheKey}' por {CACHE_TTL_HOURS}h");
            return data;
        }
        catch (RedisConnectionException ex)
        {
            _logger.LogWarning($"Redis indisponível. Fazendo fallback para chamada direta: {ex.Message}");
            return await fetchFunc();
        }
    }

    public async Task InvalidateCacheAsync(string pattern, string clienteId)
    {
        try
        {
            await _redisCache.DeleteByPatternAsync(pattern);
            _logger.LogInformation($"Cache invalidado para padrão '{pattern}' (cliente: {clienteId})");
        }
        catch (Exception ex)
        {
            _logger.LogWarning($"Erro ao invalidar cache: {ex.Message}");
        }
    }

    // Exemplo de uso: Buscar endereço por CEP
    public async Task<EnderecoModel> GetAddressByCepAsync(string cep, string clienteId)
    {
        var cacheKey = $"cep:{cep}";

        return await GetOrFetchAsync(
            cacheKey,
            async () =>
            {
                var response = await _httpClientFactory
                    .CreateClient("ExternalApi")
                    .GetAsync($"https://viacep.com.br/ws/{cep}/json/");

                response.EnsureSuccessStatusCode();
                var json = await response.Content.ReadAsStringAsync();
                return JsonSerializer.Deserialize<EnderecoModel>(json);
            },
            clienteId
        );
    }
}
```

**Exemplos**:
- ✓ Válido: CEP consultado às 10:00, cacheado até 10:00 do dia seguinte
- ✓ Válido: Redis indisponível → chamada direta à API externa (fallback)
- ✓ Válido: Invalidar padrão `cep:*` manualmente quando necessário

---

### RN-INT-114-05: Power BI Dataset Atualizado Diariamente via Hangfire

**Descrição**: Publicar automaticamente datasets em Power BI diariamente às 05h UTC via Hangfire. Suportar agendamento condicional e retry automático.

**Justificativa**:
- Dashboards sempre atualizados para executivos
- Reduz operação manual (zero-touch)
- Cronograma fora do horário comercial
- Retry automático para falhas transitórias

**Implementação**:
```csharp
public class PowerBiPublishingService
{
    private readonly IPowerBiClient _powerBiClient;
    private readonly IDataWarehouseRepository _dwRepository;
    private readonly ILogger<PowerBiPublishingService> _logger;

    public void ScheduleHangfireJob()
    {
        // Agendar para 05h UTC todos os dias
        RecurringJob.AddOrUpdate<PowerBiPublishingService>(
            "powerbi-daily-publish",
            service => service.PublishDatasetAsync(),
            Cron.Daily(5, 0),
            TimeZoneInfo.Utc
        );
    }

    public async Task PublishDatasetAsync()
    {
        try
        {
            _logger.LogInformation("Iniciando publicação diária de dataset Power BI");

            var dataset = await BuildDatasetAsync();

            var uploadResult = await _powerBiClient.UploadDatasetAsync(dataset);

            if (!uploadResult.Success)
            {
                throw new PowerBiException($"Upload falhou: {uploadResult.ErrorMessage}");
            }

            // Fazer refresh do dataset
            var refreshResult = await _powerBiClient.RefreshDatasetAsync(uploadResult.DatasetId);

            _logger.LogInformation($"Dataset publicado com sucesso. ID: {uploadResult.DatasetId}");
        }
        catch (Exception ex)
        {
            _logger.LogError($"Erro ao publicar dataset Power BI: {ex.Message}");
            throw; // Hangfire fará retry automático
        }
    }

    private async Task<PowerBiDataset> BuildDatasetAsync()
    {
        // Extrair dados do DataWarehouse
        var invoices = await _dwRepository.GetAllInvoicesAsync();
        var consumptions = await _dwRepository.GetAllConsumptionsAsync();
        var audits = await _dwRepository.GetAllAuditsAsync();

        var dataset = new PowerBiDataset
        {
            Name = $"IControlIT-Dataset-{DateTime.UtcNow:yyyyMMdd}",
            Tables = new[]
            {
                new PowerBiTable
                {
                    Name = "Faturas",
                    Rows = invoices.Select(i => new
                    {
                        i.Id,
                        i.NumeroFatura,
                        i.DataEmissao,
                        i.Valor,
                        i.Status
                    }).ToList()
                },
                new PowerBiTable
                {
                    Name = "Consumo",
                    Rows = consumptions.Select(c => new
                    {
                        c.Id,
                        c.DataConsumo,
                        c.Quantidade,
                        c.Valor
                    }).ToList()
                }
            }
        };

        return dataset;
    }
}
```

**Exemplos**:
- ✓ Válido: Job agendado para 05:00 UTC todos os dias
- ✓ Válido: Erro transitório → Hangfire retry automático (3 vezes)
- ✓ Válido: Dataset publicado e refresh iniciado

---

### RN-INT-114-06: Webhooks Devem Validar Assinatura HMAC-SHA256

**Descrição**: Toda webhook publicada deve ser validada com assinatura HMAC-SHA256 usando chave secreta do cliente. Rejeitar webhooks com assinatura inválida.

**Justificativa**:
- Segurança: Garantir origem da webhook
- Conformidade: Evitar injeção de dados maliciosos
- Auditoria: Rastrear todas as webhooks recebidas

**Implementação**:
```csharp
public class WebhookValidationService
{
    private readonly IWebhookConfigRepository _webhookConfigRepository;
    private readonly ILogger<WebhookValidationService> _logger;

    public async Task<WebhookValidationResult> ValidateWebhookAsync(
        string clienteId,
        string webhookPayload,
        string receivedSignature)
    {
        var config = await _webhookConfigRepository.GetByClientAsync(clienteId);

        if (config == null)
        {
            return new WebhookValidationResult
            {
                IsValid = false,
                Reason = "Webhook configuration not found for client"
            };
        }

        // Computar assinatura esperada
        var expectedSignature = ComputeHmacSha256(webhookPayload, config.SecretKey);

        // Comparação timing-safe (evita timing attacks)
        bool isValid = ConstantTimeComparison(receivedSignature, expectedSignature);

        if (!isValid)
        {
            _logger.LogWarning($"Webhook validation failed for client '{clienteId}'. Expected: {expectedSignature}, Received: {receivedSignature}");
        }

        return new WebhookValidationResult
        {
            IsValid = isValid,
            Reason = isValid ? "Valid signature" : "Invalid signature"
        };
    }

    private string ComputeHmacSha256(string payload, string secretKey)
    {
        using (var hmac = new System.Security.Cryptography.HMACSHA256(
            System.Text.Encoding.UTF8.GetBytes(secretKey)))
        {
            var hash = hmac.ComputeHash(System.Text.Encoding.UTF8.GetBytes(payload));
            return Convert.ToHexString(hash).ToLower();
        }
    }

    private bool ConstantTimeComparison(string a, string b)
    {
        // Evitar timing attacks comparando todos os bytes
        if (a.Length != b.Length)
            return false;

        int result = 0;
        for (int i = 0; i < a.Length; i++)
        {
            result |= a[i] ^ b[i];
        }

        return result == 0;
    }
}

public class WebhookValidationResult
{
    public bool IsValid { get; set; }
    public string Reason { get; set; }
}
```

**Exemplos**:
- ✓ Válido: Webhook com assinatura HMAC-SHA256 correta → aceita
- ✗ Inválido: Webhook sem assinatura ou assinatura incorreta → rejeitada (HTTP 401)

---

### RN-INT-114-07: API Gateway Rate Limiting (1.000 req/min por Cliente)

**Descrição**: API Gateway implementar rate limiting de 1.000 requisições por minuto por cliente. Excesso retorna HTTP 429 (Too Many Requests).

**Justificativa**:
- Evitar abuso e DDoS
- Justo entre clientes
- Transparente: Cliente informado de limite via headers

**Implementação**:
```csharp
public class RateLimitingMiddleware
{
    private readonly RequestDelegate _next;
    private readonly IRedisCache _redisCache;
    private readonly ILogger<RateLimitingMiddleware> _logger;
    private const int MAX_REQUESTS_PER_MINUTE = 1000;

    public RateLimitingMiddleware(
        RequestDelegate next,
        IRedisCache redisCache,
        ILogger<RateLimitingMiddleware> logger)
    {
        _next = next;
        _redisCache = redisCache;
        _logger = logger;
    }

    public async Task InvokeAsync(HttpContext context)
    {
        var clienteId = context.User.FindFirst("ClienteId")?.Value ?? "anonymous";
        var clientKey = $"ratelimit:{clienteId}:{DateTime.UtcNow:yyyyMMddHHmm}";

        try
        {
            // Incrementar contador
            var requestCount = await _redisCache.IncrementAsync(clientKey);

            if (requestCount == 1)
            {
                // Primeira requisição do minuto, setar expiração
                await _redisCache.ExpireAsync(clientKey, TimeSpan.FromMinutes(1));
            }

            // Adicionar headers informativos
            context.Response.Headers.Add("X-RateLimit-Limit", MAX_REQUESTS_PER_MINUTE.ToString());
            context.Response.Headers.Add("X-RateLimit-Remaining",
                (MAX_REQUESTS_PER_MINUTE - requestCount).ToString());
            context.Response.Headers.Add("X-RateLimit-Reset",
                DateTime.UtcNow.AddMinutes(1).ToString("O"));

            if (requestCount > MAX_REQUESTS_PER_MINUTE)
            {
                _logger.LogWarning($"Rate limit excedido para cliente '{clienteId}'. " +
                    $"Requisições: {requestCount}/{MAX_REQUESTS_PER_MINUTE}");

                context.Response.StatusCode = 429;
                context.Response.ContentType = "application/json";

                await context.Response.WriteAsJsonAsync(new
                {
                    error = "Too Many Requests",
                    message = $"Rate limit of {MAX_REQUESTS_PER_MINUTE} requests per minute exceeded",
                    retryAfter = 60
                });

                return;
            }

            await _next(context);
        }
        catch (Exception ex)
        {
            _logger.LogError($"Erro no middleware de rate limiting: {ex.Message}");
            await _next(context);
        }
    }
}
```

**Exemplos**:
- ✓ Válido: Cliente com 500 req/min → responde 200 com headers informativos
- ✓ Válido: Cliente com 1.000 req/min → responde 200 na 1.000ª, 429 na 1.001ª
- ✗ Inválido: Tentativa de 1.100 req/min → primeiras 1.000 aceitas, demais retornam 429

---

### RN-INT-114-08: ETL Deve Processar em Lotes de 10.000 Registros

**Descrição**: Processamento ETL para DataWarehouse deve dividir carga em lotes de 10.000 registros, com logging de progresso e suporte a resume automático em caso de falha.

**Justificativa**:
- Evita consumo excessivo de memória
- Permite paralelização
- Resume em caso de falha (idempotência)

**Implementação**:
```csharp
public class EtlProcessingService
{
    private readonly IDataWarehouseRepository _dwRepository;
    private readonly ISourceDataRepository _sourceRepository;
    private readonly ILogger<EtlProcessingService> _logger;
    private const int BATCH_SIZE = 10000;

    public async Task ProcessInvoicesAsync(string processId, int? resumeFromBatch = null)
    {
        _logger.LogInformation($"Iniciando ETL para Faturas. ProcessId: {processId}");

        var startBatch = resumeFromBatch ?? 0;
        var processedRecords = 0;
        var failedRecords = 0;

        try
        {
            var totalRecords = await _sourceRepository.CountInvoicesAsync();
            var totalBatches = (int)Math.Ceiling((double)totalRecords / BATCH_SIZE);

            for (int batch = startBatch; batch < totalBatches; batch++)
            {
                try
                {
                    var sourceData = await _sourceRepository.GetInvoicesAsync(
                        offset: batch * BATCH_SIZE,
                        limit: BATCH_SIZE
                    );

                    var transformedData = sourceData.Select(TransformInvoice).ToList();

                    await _dwRepository.InsertInvoicesBatchAsync(transformedData);

                    processedRecords += sourceData.Count;

                    _logger.LogInformation(
                        $"Batch {batch + 1}/{totalBatches} processado. " +
                        $"Progresso: {processedRecords}/{totalRecords} registros");
                }
                catch (Exception batchEx)
                {
                    failedRecords += BATCH_SIZE;
                    _logger.LogError($"Erro ao processar batch {batch}: {batchEx.Message}");

                    // Registrar para resume
                    await _dwRepository.SaveEtlCheckpointAsync(
                        new EtlCheckpoint
                        {
                            ProcessId = processId,
                            Batch = batch,
                            Status = "failed",
                            Error = batchEx.Message,
                            Timestamp = DateTime.UtcNow
                        }
                    );

                    throw; // Rethrow para que sistema de retry tente novamente
                }
            }

            _logger.LogInformation(
                $"ETL concluído. Processados: {processedRecords}, " +
                $"Falhados: {failedRecords}");
        }
        catch (Exception ex)
        {
            _logger.LogError($"ETL falhou de forma irrecuperável: {ex.Message}");
            throw;
        }
    }

    private InvoiceDataWarehouseModel TransformInvoice(InvoiceSourceModel source)
    {
        return new InvoiceDataWarehouseModel
        {
            Id = Guid.NewGuid(),
            OriginalId = source.Id,
            NumeroFatura = source.NumeroFatura,
            DataEmissao = source.DataEmissao,
            DataVencimento = source.DataVencimento,
            Valor = source.Valor,
            Desconto = source.Desconto ?? 0,
            ValorLiquido = source.Valor - (source.Desconto ?? 0),
            ClienteId = source.ClienteId,
            Status = source.Status,
            LoadDate = DateTime.UtcNow
        };
    }
}
```

**Exemplos**:
- ✓ Válido: ETL processa 100.000 registros em 10 batches de 10.000
- ✓ Válido: Falha no batch 3 → sistema registra checkpoint, próxima execução resume do batch 3
- ✓ Válido: Logging detalhado de progresso a cada batch

---

### RN-INT-114-09: Message Queue Deve Garantir Entrega (at-least-once)

**Descrição**: Azure Service Bus implementar garantia de entrega at-least-once com Dead Letter Queue para mensagens que falharem permanentemente.

**Justificativa**:
- Crítico para operações financeiras
- DLQ permite investigação de falhas
- Timeout configurável por tipo de evento

**Implementação**:
```csharp
public class AzureServiceBusPublisher
{
    private readonly ServiceBusClient _serviceBusClient;
    private readonly ILogger<AzureServiceBusPublisher> _logger;
    private const int MAX_DELIVERY_ATTEMPTS = 10;
    private const int LOCK_DURATION_SECONDS = 300;

    public async Task PublishEventAsync<T>(
        string topicName,
        T eventData,
        string clienteId) where T : class
    {
        try
        {
            var sender = _serviceBusClient.CreateSender(topicName);

            var json = JsonSerializer.Serialize(eventData);
            var message = new ServiceBusMessage(json)
            {
                Subject = typeof(T).Name,
                ContentType = "application/json",
                UserProperties =
                {
                    ["ClienteId"] = clienteId,
                    ["Timestamp"] = DateTime.UtcNow.ToString("O"),
                    ["MessageId"] = Guid.NewGuid().ToString()
                }
            };

            // Enviar com timeout de 30 segundos
            var cts = new CancellationTokenSource(TimeSpan.FromSeconds(30));
            await sender.SendMessageAsync(message, cts.Token);

            _logger.LogInformation(
                $"Evento '{typeof(T).Name}' publicado no tópico '{topicName}'. " +
                $"Cliente: {clienteId}");
        }
        catch (ServiceBusException ex) when (ex.IsTransient)
        {
            _logger.LogWarning($"Erro transitório ao publicar evento: {ex.Message}. Retry automático...");
            throw; // Deixar para Hangfire fazer retry
        }
    }

    public async Task SetupSubscriptionAsync(
        string topicName,
        string subscriptionName,
        Func<ServiceBusReceivedMessage, Task> handler)
    {
        var processor = _serviceBusClient.CreateProcessor(
            topicName,
            subscriptionName,
            new ServiceBusProcessorOptions
            {
                MaxConcurrentCalls = 10,
                AutoCompleteMessages = false,
                ReceiveMode = ServiceBusReceiveMode.PeekLock
            }
        );

        processor.ProcessMessageAsync += async args =>
        {
            try
            {
                await handler(args.Message);
                await args.CompleteMessageAsync();
            }
            catch (Exception ex)
            {
                _logger.LogError($"Erro ao processar mensagem: {ex.Message}");

                // Contar tentativas
                var deliveryCount = args.Message.DeliveryCount;

                if (deliveryCount >= MAX_DELIVERY_ATTEMPTS)
                {
                    // Enviar para DLQ
                    await args.DeadLetterMessageAsync(
                        deadLetterReason: "Max delivery attempts exceeded",
                        deadLetterErrorDescription: ex.Message);

                    _logger.LogError(
                        $"Mensagem movida para DLQ após {MAX_DELIVERY_ATTEMPTS} tentativas");
                }
                else
                {
                    // Rejeitar para retry automático
                    await args.AbandonMessageAsync();
                }
            }
        };

        processor.ProcessErrorAsync += args =>
        {
            _logger.LogError(
                $"Erro fatal na subscrição '{subscriptionName}': {args.Exception?.Message}");
            return Task.CompletedTask;
        };

        await processor.StartProcessingAsync();
    }
}
```

**Exemplos**:
- ✓ Válido: Evento publicado, subscriptor processa com sucesso → Complete
- ✓ Válido: Erro transitório (timeout) → Abandon, Azure Service Bus retry automático
- ✓ Válido: 10 falhas permanentes → Dead Letter Queue para investigação

---

### RN-INT-114-10: Auditoria de Todas as Integrações Externas

**Descrição**: Toda chamada a sistemas externos (APIs, RPA, Email, BI) deve ser registrada em auditoria com: tipo de integração, timestamp, resultado (sucesso/falha), dados relevantes, usuário, cliente. Retenção: 5 anos.

**Justificativa**:
- Conformidade LGPD/SOX
- Rastreabilidade de operações críticas
- Detecção de anomalias
- Investigação de incidents

**Implementação**:
```csharp
public class IntegrationAuditService
{
    private readonly IAuditRepository _auditRepository;
    private readonly ILogger<IntegrationAuditService> _logger;

    public async Task LogIntegrationAsync(
        string integrationType,
        string operationName,
        bool success,
        string clienteId,
        string userId,
        Dictionary<string, object> relevantData,
        Exception exception = null)
    {
        var auditEntry = new IntegrationAuditLog
        {
            Id = Guid.NewGuid(),
            IntegrationType = integrationType, // "RPA", "EMAIL", "API", "BI", "WEBHOOK"
            OperationName = operationName, // "ImportarFaturaVivo", "EnviarRelatório", etc
            Timestamp = DateTime.UtcNow,
            Success = success,
            ClienteId = clienteId,
            UserId = userId,
            RelevantData = JsonSerializer.Serialize(relevantData),
            ErrorMessage = exception?.Message,
            StackTrace = exception?.StackTrace,
            RetentionExpiry = DateTime.UtcNow.AddYears(5)
        };

        try
        {
            await _auditRepository.SaveAsync(auditEntry);

            _logger.LogInformation(
                $"Auditoria registrada: {integrationType}/{operationName} - " +
                $"Resultado: {(success ? "SUCESSO" : "FALHA")} - " +
                $"Cliente: {clienteId}");
        }
        catch (Exception ex)
        {
            _logger.LogError($"Erro ao registrar auditoria: {ex.Message}");
            // Não falhar a operação principal por erro de auditoria
        }
    }
}

public class IntegrationAuditLog
{
    public Guid Id { get; set; }
    public string IntegrationType { get; set; }
    public string OperationName { get; set; }
    public DateTime Timestamp { get; set; }
    public bool Success { get; set; }
    public string ClienteId { get; set; }
    public string UserId { get; set; }
    public string RelevantData { get; set; }
    public string ErrorMessage { get; set; }
    public string StackTrace { get; set; }
    public DateTime RetentionExpiry { get; set; }
}
```

**Exemplos**:
- ✓ Válido: RPA importa 50 faturas da Vivo → auditado com número de registros
- ✓ Válido: Email de alerta falha → auditado com motivo da falha
- ✓ Válido: Consulta de registros com 5+ anos → retidos (até expiry)

---

## 3. REFERÊNCIAS AO LEGADO

### 3.1 Banco de Dados Legado

**Banco**: `IC1_Producao` (VB.NET)

**Tabelas Relacionadas**:

| Tabela | Descrição | Campo Chave | Uso no Modernizado |
|--------|-----------|-------------|-------------------|
| `Integracoes` | Config de integrações RPA | `Id_Integracao` | Migrar para entidade `IntegrationConfiguration` |
| `IntegracaoExecucao` | Log de execução RPA | `Id_Execucao` | Migrar para `IntegrationExecutionLog` |
| `EmailTemplate` | Templates de email | `Id_Template` | Reutilizar com adaptações |
| `EmailSent` | Log de emails enviados | `Id_Email` | Migrar para auditoria |
| `CacheConfig` | Configuração de cache | `Id_Cache` | Mapear para Redis keys |
| `PowerBiDataset` | Controle de datasets | `Id_Dataset` | Persistir em Power BI |
| `Webhooks` | Configuração de webhooks | `Id_Webhook` | Entidade `WebhookConfiguration` |

**Banco de Dados Legado - DDL Principal**:

```sql
CREATE TABLE [dbo].[Integracoes](
    [Id_Integracao] [int] IDENTITY(1,1) NOT NULL,
    [Nome] [varchar](100) NOT NULL,
    [Tipo] [varchar](50) NOT NULL, -- RPA, EMAIL, API, BI
    [ClienteId] [int] NOT NULL,
    [URL] [varchar](500),
    [Username] [varchar](100),
    [Senha] [varchar](500),
    [Ativa] [bit] NOT NULL DEFAULT 1,
    [DataCriacao] [datetime] NOT NULL DEFAULT GETDATE(),
    [DataAtualizacao] [datetime],
    CONSTRAINT [PK_Integracoes] PRIMARY KEY CLUSTERED ([Id_Integracao] ASC),
    CONSTRAINT [FK_Integracoes_Clientes] FOREIGN KEY ([ClienteId])
        REFERENCES [dbo].[Clientes]([Id_Cliente])
)

CREATE TABLE [dbo].[IntegracaoExecucao](
    [Id_Execucao] [int] IDENTITY(1,1) NOT NULL,
    [Id_Integracao] [int] NOT NULL,
    [DataExecucao] [datetime] NOT NULL DEFAULT GETDATE(),
    [Sucesso] [bit] NOT NULL,
    [MensagemErro] [varchar](max),
    [TotalRegistros] [int],
    [RegistrosProcessados] [int],
    CONSTRAINT [PK_IntegracaoExecucao] PRIMARY KEY CLUSTERED ([Id_Execucao] ASC),
    CONSTRAINT [FK_IntegracaoExecucao_Integracoes] FOREIGN KEY ([Id_Integracao])
        REFERENCES [dbo].[Integracoes]([Id_Integracao])
)

CREATE TABLE [dbo].[EmailTemplate](
    [Id_Template] [int] IDENTITY(1,1) NOT NULL,
    [NomeTemplate] [varchar](100) NOT NULL,
    [Assunto] [varchar](500) NOT NULL,
    [Corpo] [varchar](max) NOT NULL,
    [ClienteId] [int] NOT NULL,
    [Ativo] [bit] DEFAULT 1,
    CONSTRAINT [PK_EmailTemplate] PRIMARY KEY CLUSTERED ([Id_Template] ASC)
)

CREATE TABLE [dbo].[Webhooks](
    [Id_Webhook] [int] IDENTITY(1,1) NOT NULL,
    [ClienteId] [int] NOT NULL,
    [URL] [varchar](500) NOT NULL,
    [Evento] [varchar](100) NOT NULL,
    [ChaveSecreta] [varchar](500) NOT NULL,
    [Ativa] [bit] DEFAULT 1,
    CONSTRAINT [PK_Webhooks] PRIMARY KEY CLUSTERED ([Id_Webhook] ASC)
)
```

### 3.2 Telas ASPX Legado

| Página | Função | Tela Moderna |
|--------|--------|------------|
| `IntegracaoList.aspx` | Listar integrações | `/integracoes` (Angular) |
| `IntegracaoForm.aspx` | CRUD de integração | `/integracoes/{id}` |
| `IntegracaoExecucao.aspx` | Histórico de execuções | `/integracoes/{id}/execucoes` |
| `EmailTemplateList.aspx` | Listar templates | `/emails/templates` |
| `WebhookConfig.aspx` | Configurar webhooks | `/webhooks` |

### 3.3 WebServices Legado

| Método | Endpoint Legado | Endpoint Moderno |
|--------|-----------------|------------------|
| `ExecutarRpa()` | POST `WsIntegracao.asmx/ExecutarRpa` | POST `/api/integracoes/rpa/executar` |
| `EnviarEmail()` | POST `WsEmail.asmx/EnviarEmail` | POST `/api/integracoes/email/enviar` |
| `ListarIntegracoes()` | GET `WsIntegracao.asmx/ListarIntegracoes` | GET `/api/integracoes` |

---

## 4. INTEGRAÇÕES OBRIGATÓRIAS

### 4.1 Central de Funcionalidades (Feature Flags)

**Feature Keys Obrigatórias**:

```json
{
    "features": [
        {
            "featureKey": "INT_RPA_ENABLED",
            "nome": "RPA - Importação de Faturas",
            "descricao": "Habilita automação RPA para importação de faturas de operadoras",
            "habilitado": true,
            "isSystemFeature": false,
            "availableForTenants": ["all"]
        },
        {
            "featureKey": "INT_EMAIL_ENABLED",
            "nome": "Email Automático",
            "descricao": "Habilita envio automático de emails com templates",
            "habilitado": true,
            "isSystemFeature": false
        },
        {
            "featureKey": "INT_CACHE_ENABLED",
            "nome": "Cache Distribuído",
            "descricao": "Habilita cache Redis para APIs externas",
            "habilitado": true,
            "isSystemFeature": true
        },
        {
            "featureKey": "INT_POWERBI_ENABLED",
            "nome": "Power BI Integration",
            "descricao": "Habilita publicação de datasets em Power BI",
            "habilitado": true,
            "isSystemFeature": false
        },
        {
            "featureKey": "INT_WEBHOOKS_ENABLED",
            "nome": "Webhooks",
            "descricao": "Habilita sistema de webhooks para eventos",
            "habilitado": true,
            "isSystemFeature": false
        }
    ]
}
```

### 4.2 Internacionalização (i18n)

**Chaves de Tradução Obrigatórias** (português e inglês):

```json
{
    "integracoes": {
        "titulo": "Integrações",
        "subtitulo": "Gerenciar integrações externas e automações",
        "form": {
            "nome": "Nome da Integração",
            "tipo": "Tipo",
            "tipoRpa": "RPA (Automação Robótica)",
            "tipoEmail": "Email",
            "tipoApi": "API",
            "tipoBi": "Business Intelligence",
            "url": "URL/Endpoint",
            "usuario": "Usuário",
            "senha": "Senha",
            "ativa": "Ativa"
        },
        "messages": {
            "sucessoAoSalvar": "Integração salva com sucesso",
            "erroAoSalvar": "Erro ao salvar integração",
            "sucessoAoExcluir": "Integração excluída com sucesso",
            "erroAoExcluir": "Erro ao excluir integração",
            "rpaEmExecucao": "RPA em execução",
            "rpaCompleto": "RPA concluído com sucesso",
            "emailEnviado": "Email enviado com sucesso",
            "erroEnvioEmail": "Erro ao enviar email"
        },
        "execucoes": {
            "titulo": "Histórico de Execuções",
            "dataExecucao": "Data de Execução",
            "resultado": "Resultado",
            "registrosProcessados": "Registros Processados",
            "sucesso": "Sucesso",
            "falha": "Falha"
        },
        "validacao": {
            "nomeObrigatorio": "Nome da integração é obrigatório",
            "tipoObrigatorio": "Tipo de integração é obrigatório",
            "urlObrigatoria": "URL é obrigatória",
            "usuarioObrigatorio": "Usuário é obrigatório",
            "senhaObrigatoria": "Senha é obrigatória"
        }
    },
    "emails": {
        "templates": {
            "titulo": "Templates de Email",
            "fatura": "Fatura Importada",
            "alerta": "Alerta de Consumo",
            "relatorio": "Relatório Executivo"
        }
    },
    "webhooks": {
        "titulo": "Webhooks",
        "config": "Configuração de Webhooks",
        "url": "URL de Callback",
        "evento": "Evento",
        "chaveSecreta": "Chave Secreta"
    }
}
```

### 4.3 Auditoria

**Operações Auditadas** (RN-INT-114-10):

| Operação | Código | Dados Registrados |
|----------|--------|-------------------|
| Criar integração | `INT_INTEGRACAO_CREATE` | Nome, Tipo, Cliente, URL |
| Editar integração | `INT_INTEGRACAO_UPDATE` | Campos alterados, Antes/Depois |
| Excluir integração | `INT_INTEGRACAO_DELETE` | ID, Nome, Cliente |
| Executar RPA | `INT_RPA_EXECUTE` | ID, Data Início, Data Fim, Total Registros, Resultado |
| Enviar Email | `INT_EMAIL_SEND` | Remetente, Destinatário, Assunto, Resultado |
| Parser Email | `INT_EMAIL_PARSE` | Remetente, Dados Extraídos, Resultado |
| Cache Hit/Miss | `INT_CACHE_OPERATION` | Chave, Tipo (Hit/Miss/Invalidate) |
| Power BI Publish | `INT_POWERBI_PUBLISH` | Dataset ID, Registros, Data |
| Webhook Received | `INT_WEBHOOK_RECEIVED` | URL, Evento, Assinatura (válida/inválida) |
| ETL Execution | `INT_ETL_EXECUTE` | Batch, Total Registros, Processados, Falhas |
| Message Queue | `INT_QUEUE_MESSAGE` | Topic, Tipo, Resultado |

**Retenção**: 5 anos (conforme LGPD/SOX)

### 4.4 Controle de Acesso (RBAC)

**Permissões Obrigatórias**:

| Permissão | Descrição | Perfis |
|-----------|-----------|--------|
| `int:integracao:read` | Visualizar integrações | Administrador, Gerente Técnico |
| `int:integracao:create` | Criar integração | Administrador |
| `int:integracao:update` | Editar integração | Administrador |
| `int:integracao:delete` | Excluir integração | Administrador |
| `int:rpa:execute` | Executar RPA manualmente | Administrador, Operador |
| `int:email:send` | Enviar email manual | Administrador, Operador |
| `int:email:template:manage` | Gerenciar templates | Administrador |
| `int:webhook:read` | Visualizar webhooks | Administrador, Desenvolvedor |
| `int:webhook:create` | Criar webhook | Administrador |
| `int:webhook:delete` | Excluir webhook | Administrador |
| `int:powerbi:publish` | Publicar em Power BI | Administrador, BI Analyst |
| `int:audit:read` | Visualizar auditoria | Administrador, Auditor |

---

## 5. ENDPOINTS DA API

### 5.1 CRUD Principal

| Método | Endpoint | Descrição | Permissão |
|--------|----------|-----------|-----------|
| GET | `/api/integracoes` | Listar integrações | `int:integracao:read` |
| GET | `/api/integracoes/{id}` | Obter integração | `int:integracao:read` |
| POST | `/api/integracoes` | Criar integração | `int:integracao:create` |
| PUT | `/api/integracoes/{id}` | Atualizar integração | `int:integracao:update` |
| DELETE | `/api/integracoes/{id}` | Excluir integração | `int:integracao:delete` |

### 5.2 Operações Especiais

| Método | Endpoint | Descrição | Permissão |
|--------|----------|-----------|-----------|
| POST | `/api/integracoes/rpa/executar` | Executar RPA manualmente | `int:rpa:execute` |
| GET | `/api/integracoes/{id}/execucoes` | Listar execuções RPA | `int:integracao:read` |
| POST | `/api/integracoes/email/enviar` | Enviar email | `int:email:send` |
| POST | `/api/integracoes/email/parse` | Fazer parse de email | `int:email:send` |
| GET | `/api/integracoes/cache/{key}` | Obter valor do cache | `int:integracao:read` |
| DELETE | `/api/integracoes/cache/{key}` | Invalidar cache | `int:integracao:update` |
| POST | `/api/integracoes/powerbi/publish` | Publicar dataset Power BI | `int:powerbi:publish` |
| GET | `/api/integracoes/powerbi/status` | Status do dataset | `int:powerbi:publish` |
| POST | `/api/integracoes/webhook/registrar` | Registrar webhook | `int:webhook:create` |
| GET | `/api/integracoes/webhook` | Listar webhooks | `int:webhook:read` |
| DELETE | `/api/integracoes/webhook/{id}` | Excluir webhook | `int:webhook:delete` |
| POST | `/api/integracoes/etl/executar` | Executar ETL | `int:integracao:update` |
| GET | `/api/integracoes/etl/status` | Status ETL | `int:integracao:read` |
| POST | `/api/integracoes/queue/publicar` | Publicar mensagem | `int:integracao:update` |
| GET | `/api/integracoes/status` | Status de todas integrações | `int:integracao:read` |

---

## 6. FLUXOS PRINCIPAIS

### 6.1 Fluxo de Importação RPA de Faturas

```
Usuario acessa /integracoes/rpa
    |
    v
Seleciona operadora (Vivo, Claro, TIM, Oi)
    |
    v
Clica "Executar RPA Agora"
    |
    v
Validar horário (deve estar entre 22h-6h) - RN-INT-114-01
    |
    +--- NÃO (14h) ---> Agendar para próximas 22h
    |
    v (SIM)
Iniciar Selenium/Playwright
    |
    v
Acessar portal de fatura com credenciais
    |
    v
Extrair números de faturas, período, valor
    |
    v
Auditoria: INT_RPA_EXECUTE - sucesso - RN-INT-114-10
    |
    v
Armazenar em banco de dados (tabela Faturas)
    |
    v
Publicar evento no Azure Service Bus - RN-INT-114-09
    |
    v
Retornar resultado ao usuário
```

### 6.2 Fluxo de Envio de Email Automático

```
Sistema dispara evento de fatura importada
    |
    v
Hangfire job: "EnviarEmailFatura"
    |
    v
Compilar dados da fatura
    |
    v
Validar cliente e obter logo - RN-INT-114-02
    |
    v
Renderizar template HTML com logo
    |
    v
Validar remetente contra whitelist/blacklist - RN-INT-114-03
    |
    v
Enviar via SendGrid com tracking
    |
    v
Auditoria: INT_EMAIL_SEND - result - RN-INT-114-10
    |
    v
Notificar usuário
```

### 6.3 Fluxo de Cache Distribuído

```
API chama: GetAddressByCep("01310100")
    |
    v
Computar cache key: "cep:01310100"
    |
    v
Verificar Redis
    |
    +--- HIT ---> Retornar valor cacheado (RN-INT-114-04)
    |
    v (MISS)
Chamar ViaCEP API
    |
    v
Se falha → Fallback automático (RN-INT-114-04)
    |
    v
Armazenar em Redis (TTL: 24h)
    |
    v
Retornar valor
```

### 6.4 Fluxo de Webhook com Validação HMAC

```
Sistema externo publica webhook
    |
    v
POST /api/integracoes/webhook/evento
    |
    v
Validar signature HMAC-SHA256 - RN-INT-114-06
    |
    +--- INVÁLIDO ---> Retornar HTTP 401 Unauthorized
    |
    v (VÁLIDO)
Auditoria: INT_WEBHOOK_RECEIVED - valid - RN-INT-114-10
    |
    v
Processar payload
    |
    v
Publicar em Azure Service Bus - RN-INT-114-09
    |
    v
Retornar HTTP 200 OK
```

---

## 7. SEGURANÇA

### 7.1 Proteções Implementadas

| Proteção | Descrição | Como Funciona |
|----------|-----------|---------------|
| **Validação HMAC-SHA256** (RN-INT-114-06) | Garante origem e integridade de webhooks | Signature computada e comparada em timing-safe |
| **Rate Limiting** (RN-INT-114-07) | Proteção contra DDoS e abuso | 1.000 req/min por cliente, HTTP 429 |
| **Whitelist/Blacklist Email** (RN-INT-114-03) | Evita phishing e emails maliciosos | Validação de remetente contra listas |
| **Criptografia de Credenciais** | Armazenar senhas com hash bcrypt+salt | Never plain text, sempre encrypted |
| **RBAC** (4.4) | Controle granular de acesso | 11 permissões obrigatórias |
| **Auditoria Completa** (RN-INT-114-10) | Rastreabilidade de operações | Log estruturado com retenção 5 anos |
| **Circuit Breaker** | Proteção de APIs externas | Falha rápida após N erros |
| **Retry com Backoff** | Proteção contra falhas transitórias | Exponential backoff para retries |

### 7.2 Testes de Segurança Obrigatórios

- [ ] SQL Injection em campos de entrada (nome, URL, credenciais)
- [ ] XSS em templates de email
- [ ] CSRF Protection em endpoints POST/PUT/DELETE
- [ ] Validação de permissões (RBAC)
- [ ] Teste de força bruta em credenciais
- [ ] Validação HMAC-SHA256 com assinatura falsa
- [ ] Rate limiting com requisições acima do limite
- [ ] Injeção de payload em webhooks
- [ ] Teste de acesso a integrações de outro cliente (multi-tenancy)
- [ ] Criptografia de dados em trânsito (HTTPS/TLS)

---

## 8. MÉTRICAS E INDICADORES

### 8.1 KPIs

| KPI | Meta | Medição |
|-----|------|---------|
| **Taxa de Sucesso RPA** | >= 95% | (Execuções bem-sucedidas / Total) |
| **Latência de Cache** | < 10ms | Tempo resposta Redis vs API |
| **Taxa de Entrega de Email** | >= 99% | (Emails entregues / Enviados) |
| **Uptime de Integrações** | >= 99.5% | (Tempo disponível / Tempo total) |
| **Latência Power BI** | < 5 min | Tempo entre coleta e publicação |
| **Taxa de Retry** | < 5% | (Mensagens reprocessadas / Total) |
| **Tempo ETL** | < 30 min | Para 1 milhão de registros |

### 8.2 Alertas

| Alerta | Condição | Ação |
|--------|----------|------|
| **RPA Falha** | 3 falhas consecutivas | Notificar admin, tentar próximo agendamento |
| **Taxa Cache Baixa** | Hit rate < 60% | Revisar TTL, analisar padrão de acesso |
| **Email Bounce** | > 5% de rejeição | Revisar lista de destinatários |
| **Webhook Falha** | DLQ > 100 mensagens | Investigar e reprocessar |
| **Rate Limit Excedido** | Cliente > 1.100 req/min | Notificar cliente, sugerir upgrade |
| **ETL Lento** | Batch > 5 minutos | Revisar índices, otimizar query |

---

## 9. PRÓXIMOS PASSOS

1. **Modelo de Dados**: Criar [MD-RF114](./MD-RF114-Integrações-Avançadas.md)
2. **Casos de Uso**: Criar [UC-RF114](./UC-RF114-Integrações-Avançadas.md)
3. **Workflow**: Criar [WF-RF114](./WF-RF114-Integrações-Avançadas.md)
4. **User Stories**: Criar [user-stories.yaml](./user-stories.yaml)
5. **Implementação Backend**: Repositories, Commands, Queries, Handlers
6. **Implementação Frontend**: Telas Angular para CRUD e monitoramento
7. **Testes**: Executar cenários (RPA, Email, Cache, Webhooks)
8. **Testes de Segurança**: Validar todas as proteções da seção 7.2

---

## CHANGELOG

| Versão | Data | Descrição | Autor |
|--------|------|-----------|-------|
| 1.0 | 2025-12-28 | Versão inicial com 10 regras de negócio, 14 endpoints, 4 integrações obrigatórias, fluxos ASCII, auditoria e segurança | Claude Code |

---

**Última Atualização**: 2025-12-28
**Autor**: Claude Code (IA)
**Revisão**: Pendente
**Status**: Rascunho (Aguardando UC e MD)
